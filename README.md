# ğŸš€ MedSegBench-SegLab â€” Plug-and-Play Binary & Multi-Class ğŸ§ ğŸ©º Segmentation 
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
![Python](https://img.shields.io/badge/Python-3.8+-yellow)
![PyTorch](https://img.shields.io/badge/PyTorch-ğŸ§©-red)
![Reproducible](https://img.shields.io/badge/Reproducible-Seeds%20%26%20Splits-green)
![Colab Ready](https://img.shields.io/badge/Open%20in-Colab-orange)
![MedSegBench Ready](https://img.shields.io/badge/MedSegBench-Ready-purple)

---

## ğŸŒŸ Why This Repo?

Medical image segmentation research often struggles with **non-reproducible experiments** â€” different splits, preprocessing, and logging styles make fair comparison impossible.  
**MedSegBench-SegLab** solves this by providing a **unified, reproducible, and Colab-friendly lab** ğŸ§  where every dataset follows an identical **13-step benchmark pipeline**, letting researchers simply plug in their models and compare fairly.

You focus on your model ğŸ§© â€” we handle the rest.

> ğŸ’¡ While conducting my research on developing a **TransUNet-Lite**, I originally built this notebook to **train and evaluate my own models**.  
It has since been tested on **three architectures** â€” one standard **TransUNet** and **two novel lightweight variants** that I designed during my experiments.


---

## ğŸ“¦ Whatâ€™s Inside

This repository includes complete **segmentation benchmark notebooks** built over the **MedSegBench datasets** (35+ datasets, 60,000+ medical images ğŸ¥), covering both:

- ğŸ©¸ **Binary Segmentation** â€” single foreground class (e.g., tumor vs. non-tumor)
- ğŸ©º **Multi-Class Segmentation** â€” multiple organs, lesions, or tissue regions *(coming soon...)*

Each notebook is **Colab-ready**, self-contained, and follows the exact same structure for **fair apples-to-apples model comparison** ğŸğŸ.

---

> > âš™ï¸ **Note:**  
> For each dataset notebook, Iâ€™m currently running up to **Step 5ï¸âƒ£** â€” mainly to update dataset paths, verify file structures, and ensure that all **DataLoaders** function correctly.  
> Full end-to-end runs (training â†’ evaluation â†’ visualization) will be completed later or integrated into the **Vision4Healthcare** repository.  
>  
> This phase focuses purely on the **dataset preparation and validation** ğŸ§©, while new and optimized models for **Step 6 â€” MODEL BLOCK** ğŸ§  will be introduced in a dedicated upcoming repository.

---

## ğŸ§© What Does Each Notebook Include?

Each notebook follows a **13-step universal pipeline**:

1. **Environment & Libraries** â€” Import and setup GPU, print versions  
2. **Dataset Download** â€” Fetch MedSegBench NPZ and verify MD5  
3. **Config & Reproducibility** â€” Fixed seed, configs, and environment dump  
4. **Predefined Splits** â€” Load dataset splits (no re-splitting)  
5. **Preprocessing & Augmentations** â€” Normalize and augment  
6. **ğŸ§  MODEL BLOCK** â€” âœ¨ *Your playground!* Paste your custom model here  
7. **Losses & Metrics** â€” Dice, IoU, BCE, CrossEntropy  
8. **Training & Logging** â€” AdamW, CosineLR, mixed precision, CSV logs  
9. **Plotly Curves** â€” Interactive training/validation curves  
10. **Test Evaluation** â€” Frozen checkpoint, compute metrics  
11. **Inference Speed Test** â€” Measure latency & VRAM  
12. **Threshold & Calibration** â€” PR/ROC, AUPRC, AUROC, ECE  
13. **Qualitative Visuals** â€” Image overlays, boundaries, grid outputs  

Everythingâ€”training logs, checkpoints, figures, summariesâ€”is saved automatically.  
Just modify Step 6 and re-run the notebook end-to-end!

---

## âš™ï¸ How to Run

1. Open any notebook in **Google Colab** or **Jupyter**.  
2. Set your `MEDSEGBENCH_DIR` (where datasets are cached).  
3. Go to **Step 6 â€” MODEL BLOCK** and paste your model (e.g., U-Net, TransUNet, SwinUNet).  
4. Run all cells â€” thatâ€™s it! ğŸš€  

Each notebook runs completely standalone.  
For demonstration, weâ€™ve used **TransUNet ğŸ§¬** as an example model.

---

## ğŸ§  Dataset Overview

**MedSegBench** is a large-scale collection of **35+ medical image segmentation datasets** standardized for fair benchmarking.  
It includes over **60,000+ images** from modalities like:

- ğŸ©º **Dermoscopic (ISIC 2016/2018)**
- ğŸ« **CT / MRI (Brain, Liver, Heart)**
- ğŸ©» **X-ray & Ultrasound (Chest, Abdomen, Musculoskeletal)**  

Each dataset is provided in `.npz` format with **predefined splits**, **unified resolution (128/256/512)**, and **MD5 verification** for reproducibility.

---

# ğŸ©¸ Binary Segmentation Projects

Binary segmentation focuses on separating **foreground (e.g., lesion/tumor)** from **background**, perfect for lightweight and diagnostic models.  
Each notebook here follows the 13-step standard pipeline and only changes **dataset name** and **Step 6 model**.

You can plug in **your custom architecture**, evaluate it under **identical conditions**, and visualize results with live **Plotly curves**, **Dice/IoU comparisons**, and **qualitative overlays**.  
All metrics, speed, and calibration plots are generated automatically â€” so benchmarking becomes effortless! âš¡

---

## ğŸ“˜ Projects

- **[ISIC 2016 â€” Skin Lesion Segmentation (256Ã—256) with TransUNet ğŸ”¬](https://github.com/HussamUmer/MedSegBench-SegLab/blob/main/ISIC2016_Binary_TransUNet256/README.md)**  
  <sub>Folder: `ISIC2016_Binary_TransUNet256`</sub>
- **[ISIC 2016 â€” Skin Lesion Segmentation (512Ã—512) with TransUNet ğŸ”¬](https://github.com/HussamUmer/MedSegBench-SegLab/blob/main/ISIC2016_Binary_TransUNet512/README.md)**  
  <sub>Folder: `ISIC2016_Binary_TransUNet512`</sub>
- **[Covid19RadioMSBench â€” Chest X-Ray Lung Segmentation (256Ã—256) with TransUNet ğŸ«](https://github.com/HussamUmer/MedSegBench-SegLab/tree/main/Covid19Radio_Binary_TransUNet256)**  
  <sub>Folder: `Covid19Radio_Binary_TransUNet256`</sub>
- **[Kvasir â€” Endoscopy Polyp Segmentation (256Ã—256) with TransUNet ğŸ”¬](https://github.com/HussamUmer/MedSegBench-SegLab/tree/main/Kvasir_Binary_TransUNet256)**  
  <sub>Folder: `Kvasir_Binary_TransUNet256`</sub>
- **[RoboTool â€” Endoscopic Surgical Tool Segmentation (256Ã—256) with TransUNet âš™ï¸](https://github.com/HussamUmer/MedSegBench-SegLab/tree/main/RoboTool_Binary_TransUNet256)**  
  <sub>Folder: `RoboTool_Binary_TransUNet256`</sub>
- **[Promise12 â€” Prostate MRI Segmentation (256Ã—256) with TransUNet ğŸ§¬](https://github.com/HussamUmer/MedSegBench-SegLab/tree/main/Promise12_Binary_TransUNet256)**  
  <sub>Folder: `Promise12_Binary_TransUNet256`</sub>


> (Binary segmentation notebooks coming soon... stay tuned ğŸ§©)

---

# ğŸ©º Multi-Class Segmentation Projects

Multi-class segmentation deals with **organ-level** or **region-level** predictions, where multiple anatomical structures are labeled simultaneously.  
The same 13-step framework extends naturally to multi-class datasets with per-class metrics, confusion matrices, and class-wise calibration.

> (Coming soon in v2 release â€” support for AbdomenUSMSBench, Polyp, and OrganSeg datasets ğŸ§¬)

---

## ğŸ§¾ Citation

If you use this repository or MedSegBench datasets, please cite:

> **MedSegBench: A Comprehensive Benchmark for Medical Image Segmentation Across Modalities**  
> *Zenodo DOI: [10.5281/zenodo.12662149](https://zenodo.org/records/12662149)*

---

## ğŸ’¡ Final Words

âœ¨ This project is **open for Colab**, **open for collaboration**, and **open for discovery**.  
ğŸŒ Star â­ the repo, fork it, and bring your segmentation model to life with fair benchmarking!  

> â€œOne pipeline, many datasets â€” infinite innovation.â€ ğŸ’«  
â€” *Team Vision4Healthcare*
