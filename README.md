# ğŸš€ MedSegBench-SegLab â€” Plug-and-Play Binary & Multi-Class ğŸ§ ğŸ©º Segmentation 
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
![Python](https://img.shields.io/badge/Python-3.8+-yellow)
![PyTorch](https://img.shields.io/badge/PyTorch-ğŸ§©-red)
![Reproducible](https://img.shields.io/badge/Reproducible-Seeds%20%26%20Splits-green)
![Colab Ready](https://img.shields.io/badge/Open%20in-Colab-orange)
![MedSegBench Ready](https://img.shields.io/badge/MedSegBench-Ready-purple)

---

## ğŸŒŸ Why This Repo?

Medical image segmentation research often struggles with **non-reproducible experiments** â€” different splits, preprocessing, and logging styles make fair comparison impossible.  
**MedSegBench-SegLab** solves this by providing a **unified, reproducible, and Colab-friendly lab** ğŸ§  where every dataset follows an identical **13-step benchmark pipeline**, letting researchers simply plug in their models and compare fairly.

You focus on your model ğŸ§© â€” we handle the rest.

> ğŸ’¡ While conducting my research on developing a **TransUNet-Lite**, I originally built this notebook to **train and evaluate my own models**.  
It has since been tested on **three architectures** â€” one standard **TransUNet** and **two novel lightweight variants** that I designed during my experiments.


---

## ğŸ“¦ Whatâ€™s Inside

This repository includes complete **segmentation benchmark notebooks** built over the **MedSegBench datasets** (35+ datasets, 60,000+ medical images ğŸ¥), covering both:

- ğŸ©¸ **Binary Segmentation** â€” single foreground class (e.g., tumor vs. non-tumor)
- ğŸ©º **Multi-Class Segmentation** â€” multiple organs, lesions, or tissue regions *(coming soon...)*

Each notebook is **Colab-ready**, self-contained, and follows the exact same structure for **fair apples-to-apples model comparison** ğŸğŸ.

---

> âš™ï¸ **Note:**  
> Iâ€™ve run **each dataset notebook for 1 epoch** ğŸ§ª â€” just to confirm that all components (dataset paths, file structures, augmentations, and DataLoaders) work correctly and the pipelines execute without errors.  
> The only exception is the **Covid19Radio project**, which I havenâ€™t executed yet but am confident will work flawlessly given its identical structure.  
>  
> This limited run was purely for **functional validation** and not full model training. You can perform full training yourself directly in **Google Colab** or **Jupyter Notebook** by simply running all cells end-to-end.  
>  

---

## ğŸ§© What Does Each Notebook Include?

Each notebook follows a **13-step universal pipeline**:

1. **Environment & Libraries** â€” Import and setup GPU, print versions  
2. **Dataset Download** â€” Fetch MedSegBench NPZ and verify MD5  
3. **Config & Reproducibility** â€” Fixed seed, configs, and environment dump  
4. **Predefined Splits** â€” Load dataset splits (no re-splitting)  
5. **Preprocessing & Augmentations** â€” Normalize and augment  
6. **ğŸ§  MODEL BLOCK** â€” âœ¨ *Your playground!* Paste your custom model here  
7. **Losses & Metrics** â€” Dice, IoU, BCE, CrossEntropy  
8. **Training & Logging** â€” AdamW, CosineLR, mixed precision, CSV logs  
9. **Plotly Curves** â€” Interactive training/validation curves  
10. **Test Evaluation** â€” Frozen checkpoint, compute metrics  
11. **Inference Speed Test** â€” Measure latency & VRAM  
12. **Threshold & Calibration** â€” PR/ROC, AUPRC, AUROC, ECE  
13. **Qualitative Visuals** â€” Image overlays, boundaries, grid outputs  

Everythingâ€”training logs, checkpoints, figures, summariesâ€”is saved automatically.  
Just modify Step 6 and re-run the notebook end-to-end!

---

## âš™ï¸ How to Run

1. Open any notebook in **Google Colab** or **Jupyter**.  
2. Set your `MEDSEGBENCH_DIR` (where datasets are cached).  
3. Go to **Step 6 â€” MODEL BLOCK** and paste your model (e.g., U-Net, TransUNet, SwinUNet).  
4. Run all cells â€” thatâ€™s it! ğŸš€  

Each notebook runs completely standalone.  
For demonstration, weâ€™ve used **TransUNet ğŸ§¬** as an example model.

---

## ğŸ§  Dataset Overview

**MedSegBench** is a large-scale collection of **35+ medical image segmentation datasets** standardized for fair benchmarking.  
It includes over **60,000+ images** from modalities like:

- ğŸ©º **Dermoscopic (ISIC 2016/2018)**
- ğŸ« **CT / MRI (Brain, Liver, Heart)**
- ğŸ©» **X-ray & Ultrasound (Chest, Abdomen, Musculoskeletal)**  

Each dataset is provided in `.npz` format with **predefined splits**, **unified resolution (128/256/512)**, and **MD5 verification** for reproducibility.

---

# ğŸ©¸ Binary Segmentation Projects

Binary segmentation focuses on separating **foreground (e.g., lesion/tumor)** from **background**, perfect for lightweight and diagnostic models.  
Each notebook here follows the 13-step standard pipeline and only changes **dataset name** and **Step 6 model**.

You can plug in **your custom architecture**, evaluate it under **identical conditions**, and visualize results with live **Plotly curves**, **Dice/IoU comparisons**, and **qualitative overlays**.  
All metrics, speed, and calibration plots are generated automatically â€” so benchmarking becomes effortless! âš¡

---

## ğŸ“˜ Projects

- **[ISIC 2016 â€” Skin Lesion Segmentation (256Ã—256) with TransUNet ğŸ”¬](https://github.com/HussamUmer/MedSegBench-SegLab/blob/main/ISIC2016_Binary_TransUNet256/README.md)**  
  <sub>Folder: `ISIC2016_Binary_TransUNet256`</sub>
- **[ISIC 2016 â€” Skin Lesion Segmentation (512Ã—512) with TransUNet ğŸ”¬](https://github.com/HussamUmer/MedSegBench-SegLab/blob/main/ISIC2016_Binary_TransUNet512/README.md)**  
  <sub>Folder: `ISIC2016_Binary_TransUNet512`</sub>
- **[Covid19RadioMSBench â€” Chest X-Ray Lung Segmentation (256Ã—256) with TransUNet ğŸ«](https://github.com/HussamUmer/MedSegBench-SegLab/tree/main/Covid19Radio_Binary_TransUNet256)**  
  <sub>Folder: `Covid19Radio_Binary_TransUNet256`</sub>
- **[Kvasir â€” Endoscopy Polyp Segmentation (256Ã—256) with TransUNet ğŸ”¬](https://github.com/HussamUmer/MedSegBench-SegLab/tree/main/Kvasir_Binary_TransUNet256)**  
  <sub>Folder: `Kvasir_Binary_TransUNet256`</sub>
- **[RoboTool â€” Endoscopic Surgical Tool Segmentation (256Ã—256) with TransUNet âš™ï¸](https://github.com/HussamUmer/MedSegBench-SegLab/tree/main/RoboTool_Binary_TransUNet256)**  
  <sub>Folder: `RoboTool_Binary_TransUNet256`</sub>
- **[Promise12 â€” Prostate MRI Segmentation (256Ã—256) with TransUNet ğŸ§¬](https://github.com/HussamUmer/MedSegBench-SegLab/tree/main/Promise12_Binary_TransUNet256)**  
  <sub>Folder: `Promise12_Binary_TransUNet256`</sub>
- **[BUSI â€” Breast Ultrasound Lesion Segmentation (256Ã—256) with TransUNet ğŸ©º](https://github.com/HussamUmer/MedSegBench-SegLab/tree/main/BUSI_Binary_TransUNet256)**  
  <sub>Folder: `BUSI_Binary_TransUNet256`</sub>

> (Binary segmentation notebooks coming soon... stay tuned ğŸ§©)

---

# ğŸ©º Multi-Class Segmentation Projects

Multi-class segmentation deals with **organ-level** or **region-level** predictions, where multiple anatomical structures are labeled simultaneously.  
The same 13-step framework extends naturally to multi-class datasets with per-class metrics, confusion matrices, and class-wise calibration.

> (Coming soon in v2 release â€” support for AbdomenUSMSBench, Polyp, and OrganSeg datasets ğŸ§¬)

---

## ğŸ§  Step-6 Plug-and-Play Segmentation Models  

This folder contains ready-to-use **model blocks** for **Step 6 â€” MODEL BLOCK** of the Seg-Lab pipeline ğŸ§©.  
Each notebook is a *plug-and-play* segment that can be inserted directly into any dataset notebook (ISIC, Kvasir, BUSI â€¦).  

> âš ï¸ **Important:** These model notebooks **will not run independently**.  
> They depend on the Seg-Lab pipeline (Steps 0â€“5 & 7â€“13).  
> Always **copy the cells into Step 6** of a dataset notebook before execution.

---

### ğŸ”§ Standard Copy-Paste Flow (for all models)

Each model has **4 cells** that you must copy in order:

1ï¸âƒ£ **Cell 1/4 â€” Imports & Wrapper**  
   - Copy imports and the `SMPWrap` (or equivalent).  
   - Ensures `forward(x) â†’ {"logits": (B, C, H, W)}` for pipeline compatibility.  

2ï¸âƒ£ **Cell 2/4 â€” Builder Function**  
   - Copy the `build_*()` definition.  
   - Confirm:  
     - `in_channels = 3`  
     - `classes = C` (â†’ `1` for binary, `>1` for multiclass)  
     - `activation = None` (loss handles activation).  

3ï¸âƒ£ **Cell 3/4 â€” Instantiate & Shape Check**  
   - Paste the model-creation snippet, e.g.:  
     ```python
     model = build_unet_r34_binary()
     xb, yb = next(iter(train_loader))
     out = model(xb)
     print("logits:", tuple(out["logits"].shape))
     ```  
   - (Optional) set a tag for checkpoints/logs:  
     ```python
     MODEL_TAG = "UNet-R34"
     ```  

4ï¸âƒ£ **Cell 4/4 â€” Parameter Count (Optional)**  
   - Paste the parameter summary:  
     ```python
     num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
     print(f"[PARAMS] {MODEL_TAG}: {num_params/1e6:.2f} M")
     ```  

> âœ… Once inserted, no edits are needed â€” the pipeline automatically manages training, metrics, visualization, calibration, and speed/VRAM benchmarking.

---

## ğŸ“š Available Models

### 1ï¸âƒ£ TransUNet (Default)
Already included in every dataset notebook as the **default baseline**.  
*No copy required â€” use as is.*

---

### 2ï¸âƒ£ U-Net (R34 Encoder)
<a href="https://colab.research.google.com/github/HussamUmer/MedSegBench-SegLab/blob/main/Segmentation%20Models/U_Net.ipynb" target="_blank">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open U-Net in Colab"/>
</a>  
- Copy **Cells 1/4 â€“ 4/4** into Step 6 of your dataset notebook.

---

### 3ï¸âƒ£ U-Net++ (Dense Skip Connections)
<a href="https://colab.research.google.com/github/HussamUmer/MedSegBench-SegLab/blob/main/Segmentation%20Models/U_Net_PlusPlus.ipynb" target="_blank">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open U-Net++ in Colab"/>
</a>  
- Copy **Cells 1/4 â€“ 4/4** into Step 6 of your dataset notebook.

---

### 4ï¸âƒ£ DeepLabV3+ (ResNet-50 Backbone)
<a href="https://colab.research.google.com/github/HussamUmer/MedSegBench-SegLab/blob/main/Segmentation%20Models/DeepLabV3%2B.ipynb" target="_blank">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open DeepLabV3+ in Colab"/>
</a>  
- Copy **Cells 1/4 â€“ 4/4** into Step 6 of your dataset notebook.

---

### âœ… Before Running
- [ ] Correct `C` value (Binary â†’ 1; Multiclass â†’ #classes).  
- [ ] `forward(x)` returns `{"logits": B Ã— C Ã— H Ã— W}`.  
- [ ] `IMAGE_SIZE` matches dataset (128 / 256 / 512).  
- [ ] `AMP_ON` (mixed precision) can remain True.  

> ğŸ”§ More Step-6 plug-and-play models are coming soon! If you want a specific architecture, open a PR or request it â€” Iâ€™ll add it to the collection âœ¨


---
## ğŸ§¾ Citation

If you use this repository or MedSegBench datasets, please cite:

> **MedSegBench: A Comprehensive Benchmark for Medical Image Segmentation Across Modalities**  
> *Zenodo DOI: [10.5281/zenodo.12662149](https://zenodo.org/records/12662149)*

---

## ğŸ’¡ Final Words

âœ¨ This project is **open for Colab**, **open for collaboration**, and **open for discovery**.  
ğŸŒ Star â­ the repo, fork it, and bring your segmentation model to life with fair benchmarking!  

> â€œOne pipeline, many datasets â€” infinite innovation.â€ ğŸ’«  
â€” *Team Vision4Healthcare*
